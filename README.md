
# **Artificial Neural Network performance boost using Probabilistic Recovery with Rapid Cascade Training**


### Introduction

One of the most promising applications of Artificial Neural Networks (ANN) is pattern recognition and classification. However, neural networks have to be fairly large and complex, in order to provide robust results. In this paper, we propose a novel ANN architecture, combining two fairly small Neural Networks, where a probability term of correct classification is introduced. The second ANN is used to reclassify the potentially incorrect results, using the most probably correct results as extra training data. The method achieves a rapid decrease of the  error, in comparison to other large and complex ANN architectures with similar execution time.


### Prerequisites

[1] Python

[2] Tensorflow

[3] Keras


### Datasets 

The datasets used in this paper are the Wine, Iris, MNIST, Cifar32 and Fashion MNIST.The later can demonstrate the effectiveness of the proposed approach.


### Models

Implementations of the proposed boosting algorithm along with these models can be found at the corresponding folders


## Citation
If you use this code or the article the then please cite:

```bibtex
...
```

## Future Updates

Further support for the RNN architecture will be added
