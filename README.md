
# **Artificial Neural Network performance boost using Probabilistic Recovery with Rapid Cascade Training**

[create an anchor](#Introduction)
	
One of the most promising applications of Artificial Neural Networks (ANN) is pattern recognition and classification. However, neural networks have to be fairly large and complex, in order to provide robust results. In this paper, we propose a novel ANN architecture, combining two fairly small Neural Networks, where a probability term of correct classification is introduced. The second ANN is used to reclassify the potentially incorrect results, using the most probably correct results as extra training data. The method achieves a rapid decrease of the  error, in comparison to other large and complex ANN architectures with similar execution time.















The datasets used in this paper are wine, iris, MNIST, Cifar32 and Fashion MNIST classification problems, which can demonstrate the effectiveness of the proposed approach.
